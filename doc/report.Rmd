---
title: "The red wine quality prediction"
author: "DSCI 522 Group 311: Tao Huang, Hanying Zhang, Xugang Zhong"
date: "2020-01-24 "
output:
  github_document:
    toc: true
bibliography: ref.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(knitr)
```

## Summary

To answer the question about predicting the red wine quality based on physiochemical properties, we propose a prediction model using linear regression algorithm. Based on the 1599 samples with 11 original physiochemical features, we deployed recursive feature elimination (RFE)  to select features by recursively considering smaller and smaller sets of features. It turned out that 6 physiochemical properties is significant contributing to a better model performance. Building such model is valuable to support oenologist wine tasting evaluations and improve wine production. 


## Introduction

According to [British Columbia Wine Institute]( https://winebc.com/industry/media/quick-facts/), the BC wine industry contributes approximately $2.8 billion annually to British Columbia’s economy. To facilitate the development of BC wine industry, stakeholders are seeking a better way to improve the wine production and selling process with new techniques applied. Globally, wine certification and quality assessment are essential given this context.

Wine quality assessment basically consists of two parts: the lab test and the sensory test. Physicochemical lab tests generally characterize wine based on features such as density, pH value, acidity, sugar, and alcohol, etc. While the sensory test mainly relies on qualified experts. Due to the low interpretation of human sense, the relationship between sensory tests and the lab tests is somehow compared to a black box. The industry is curious about how ‘good’ the wine is, given the physicochemical lab test results.  Therefore, a model integrating physiochemical lab tests and sensory tests is helpful in addressing the industry concern, supporting the wine evaluation and thus improving local wine production.  
## Methodology

The data used in this project is obtained from the [University of California Irvine Machine learning Repository]( http://archive.ics.uci.edu/ml/datasets/Wine+Quality)[@cortez2009modeling][@Dua2019].  It contains 1599 samples from red wine produced in Portugal. Each sample represents 11 physiochemical properties (features) from lab tests and also the sensory results (response) ranging from 0 to 10.  


The Analysis portion of this project is done by Python. A standard scaler is used to scale all features into the same scale. To perform feature selection, we use scikit-learn's linear regression as an estimator and perform recursive feature selection. Regarding the number of features to select, we try the number from 1 to 11 (sum of features), we found that if we continute to add more features after 6, the model will stop improving. Therefore, we perform linear regression on the top six features by using scikit-learn's linear regression model.

The following Python packages were used in this project:

### R 

- testthat[@testthat]

- docopt[@docopt]

- knitr[@knitr]

- tidyverse[@tidyverse]

- janitor[@janitor]

- reshape2[@reshape2]

- viridis[@viridis]

- caret[@caret]

### Python

- docoptpython[@docoptpython]

- request[@request]

- pandas[@pandas]

- numpy[@numpy]

- altair[@altair]

- pyjanitor[@pyjanitor]

- scikit-learn[@sklearn]

## Results

By applying `sklearn`'s `Recursive Feature Selection`, we recursively fit a Linear Regression model to the data to get all the coefficients (as measures of importances). Each time, we increase the number of featuers that we like to select, from 1 to 11 (all the features). Eventually, we found after only 6 features are helping to decrease the errors, increasing the number of features selected beyond 6 will not help:

```{r feature ranking, echo=FALSE, fig.cap="Figure 1. The relationship between MSE and number of featurs", out.width = '100%'}
knitr::include_graphics("../results/ranked_features.png")
```

Now, we run `sklearn`'s `Recursive Feature Selection` again with the `n_features_to_select` explicitly set to 6, then the algorithm will fit linear regression models, remove one feature that has the smallest weight. `sklearn` recursively does this until the number of the features decrease to 6. The following are the 6 features remained eventually and their corresponding weights in ascending order:

```{r feature weight, echo=FALSE, fig.cap="Figure 2. Feature weight", out.width = '90%'}
knitr::include_graphics("../results/feature_weight_plot.png")
```

Finally, we plot the actual values on the x-axis and the predicted values on the y-axis:

```{r prediction results, echo=FALSE, fig.cap="Figure 3. Prediction results", out.width = '90%'}
knitr::include_graphics("../results/prediction_result.png")
```

Based on the plot, we can see that our model predicts well on the middle range (grades 5 and 6). However, for the low grade, the model tends to over-estimate (eg. grade 4), while for high grade wines (wine with grades 7 and 8), the model tends to under-estimate.

## Discussion:

Even without domain expertise, we all know that those physiochemical properties of wine should be good indicators of the wine qualities. The fact that the model performed well on middle range proves that the selected features are useful and a linear regression is a reasonable model to choose.

The reason that it did not perform well on low-grade and high-grade may be due to that the original training set is already not balanced enough, the data set does have more examples for the middle-grade wines and less examples for low and high grade wines, which means our model can not 'learn' enough from the low and high grade wines.

Some potential improvements can be simply oversampling the high-grade and low-grade wines to supplement the origianl dataset or to undersample the middle-grade wines in the original dataset.

## References
